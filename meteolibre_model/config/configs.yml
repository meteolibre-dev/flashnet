model_v0_mtg_meteofrance:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "endpoint"
  batch_size: 128
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gradient_clip_value: 1.0
  dataset_path: "/workspace/dataset"

model_v0_mtg_lightning:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "standard"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gradient_clip_value: 1.0
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 12
    kpi_in_channels: 1
    sat_out_channels: 12
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 4
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64

model_v0_mtg_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "standard"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gradient_clip_value: 1.0
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 12
    kpi_in_channels: 1
    sat_out_channels: 12
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64


model_v0_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  sigma_noise_input: 0.
  gradient_clip_value: 1.0
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64

model_v1_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "polynomial"
  batch_size: 128
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  sigma_noise_input: 0.01
  gradient_clip_value: 1.0
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64


model_v2_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 128
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  sigma_noise_input: 0.01
  gradient_clip_value: 1.0
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64


model_v3_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "polynomial"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  sigma_noise_input: 0.01
  gradient_clip_value: 1.0
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64
  model_correction:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 2
    num_additional_resnet_blocks: 2
    time_emb_dim: 64



model_v4_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "polynomial"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  sigma_noise_input: 0.01
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64


model_v5_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 5
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "polynomial"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  sigma_noise_input: 0.005
  gradient_clip_value: 1.0
  residual: True
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [64, 128, 256, 512]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64


model_v6_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  sigma_noise_input: 0.005
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64


model_v7_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  nb_forecast: 3
  sigma_noise_input: 0.005
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64


model_v8_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  nb_forecast: 3
  sigma_noise_input: 0.005
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 16
    kpi_in_channels: 1
    sat_out_channels: 16
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 5
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64
    causal: True


model_v9_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  nb_forecast: 3
  sigma_noise_input: 0.01
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  model:
    sat_in_channels: 17
    kpi_in_channels: 1
    sat_out_channels: 17
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 6
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64
    causal: False


model_v10_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 16
  learning_rate: 0.001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  nb_forecast: 8
  sigma_noise_input: 0.0
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  comment: "Model trained on 256x256"
  model:
    sat_in_channels: 17
    kpi_in_channels: 1
    sat_out_channels: 17
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 6
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64
    causal: True


model_v11_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 128
  learning_rate: 0.0001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  nb_forecast: 3
  sigma_noise_input: 0.01
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  comment: "retrain 128x128 model but with more time: bad result"
  model:
    sat_in_channels: 17
    kpi_in_channels: 1
    sat_out_channels: 17
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 6
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64
    causal: False


model_v12_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 64
  learning_rate: 0.0001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  nb_forecast: 3
  sigma_noise_input: 0.
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  comment: "no context training for CFG inference"
  model:
    sat_in_channels: 17
    kpi_in_channels: 1
    sat_out_channels: 17
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 6
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64
    causal: False


model_v13_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 64
  learning_rate: 0.0001
  num_epochs: 200
  seed: 42
  gen_steps: 4
  nb_forecast: 3
  sigma_noise_input: 0.
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  comment: "retrain 128x128 with lower lr 3 * 10e-4"
  model:
    sat_in_channels: 17
    kpi_in_channels: 1
    sat_out_channels: 17
    kpi_out_channels: 1
    additional_channels: 3
    features: [32, 64, 128, 256]
    context_dim: 6
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64
    causal: False

model_v14_mtg_world_lightning_shortcut:
  log_every_n_steps: 5
  save_every_n_epochs: 1
  model_dir: "models/"
  parametrization: "standard"
  interpolation: "linear"
  batch_size: 32
  learning_rate: 0.0003
  num_epochs: 200
  seed: 42
  gen_steps: 4
  nb_forecast: 3
  sigma_noise_input: 0.
  gradient_clip_value: 1.0
  residual: False
  dataset_path: "/workspace/dataset"
  comment: "retrain 128x128 with lower lr 3 * 10e-4 AND with [64, 128, 256, 512] dim"
  model:
    sat_in_channels: 17
    kpi_in_channels: 1
    sat_out_channels: 17
    kpi_out_channels: 1
    additional_channels: 3
    features: [64, 128, 256, 512]
    context_dim: 6
    embedding_dim: 128
    context_frames: 4
    num_additional_resnet_blocks: 2
    time_emb_dim: 64
    causal: False